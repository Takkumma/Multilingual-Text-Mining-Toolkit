# Multilingual Text Mining Toolkit
## Overview
A multilingual text mining toolkit built on spaCy, offering advanced features like concordancers, co-occurrence analysis, dependency parsing, and network visualization. This interactive Jupyter Notebook suite enables efficient text data preprocessing, exploration, and analysis for cross-lingual research.

## 概要
spaCyを基盤とした多言語対応のテキストマイニングツールキットです。コンコーダンス検索、共起分析、依存構造解析、ネットワーク可視化など、多様な分析機能を提供します。Jupyter Notebookベースの対話的な分析環境により、多言語に対応したテキストデータの効率的な前処理、探索的分析、検証的分析を可能にします。

## 主な機能
- **テキストファイル解析**: spaCyの統計モデルを用いたテキストの基本解析（他の分析の前提条件）
- **特徴語分析**: 品詞ごとの頻出語や単語n-gramの集計、単語リストや散布図の作成
- **コンコーダンサー**: コーパスから指定した表現をKWIC形式で出力
- **依存構造分析**: 文の依存構造の可視化、特定の依存構造を持つ単語が出現する文を抽出
- **共起語分析**: 指定した表現と文内で共起する語を集計
- **共起ネットワーク分析**: 文内での共起関係をネットワーク図に可視化

## 特徴
- テキストの一括解析と解析結果の保存機能により、効率的な分析作業が可能
- 複数の分析手法を組み合わせた多角的な分析をサポート
- Scattertext機能による版間比較など、視覚的な分析ツールを提供
- Jupyter Notebook形式での提供により、分析プロセスの管理が容易

## 技術基盤
本ツールは、自然言語処理ライブラリspaCyを基盤としています。spaCyの主な特徴は以下の通りです：

- **多言語対応**: 多数の言語に対応し、統計モデルを提供
  - spaCy本体の言語モデル
  - spacy-stanzaによる追加言語のサポート
  - 対応言語の詳細は[spaCyの公式モデル一覧](https://spacy.io/models)をご確認ください
- **Universal Dependencies準拠**: 言語間で一貫した文法アノテーションを提供
  - 品詞タグや依存関係ラベルの詳細は[Universal Dependencies](https://universaldependencies.org/)をご参照ください

## 事前準備
1. **Pythonの実行環境の構築**
   - Anacondaを使用した環境構築を推奨
   - Google Colaboratoryでの実行も可能

2. **分析スクリプトのダウンロード**
   - GitHubリポジトリから「Download ZIP」でダウンロード
   - `notebooks`フォルダを作業ディレクトリにコピー

3. **環境設定スクリプトの実行**
   - `環境設定.ipynb`を実行し、必要なライブラリと言語モデルをインストール

## ディレクトリ構成
```
nlp_text_analysis/                 # プロジェクトの作業ディレクトリ
│
├── text_data/                     # 解析対象のテキストデータを格納したディレクトリ
│   ├── corpus_spoken/            # 話し言葉コーパスデータ
│   │   ├── file1.txt             # テキストファイル
│   │   ├── file2.txt
│   │   └── ...
│   └── corpus_written/           # 書き言葉コーパスデータ
│       ├── file1.txt
│       ├── file2.txt
│       └── ...
│
├── processed_data/                # 解析結果を格納するメインディレクトリ（親ディレクトリ）
│   ├── corpus_spoken_analysis/    # 話し言葉コーパス解析結果を格納するサブディレクトリ（子）
│   │   ├── processed_20230417_123456.spacy  # 解析結果のバイナリファイル
│   │   └── processed_20230417_123456.txt    # 解析したファイル名が記載されたテキストデータ
│   └── corpus_written_processed/  # 書き言葉コーパス解析結果を格納するサブディレクトリ
│       ├── processed_20230418_987654.spacy
│       └── processed_20230418_987654.txt
│
├── テキストファイル解析.ipynb     # テキストデータ解析スクリプト（他の分析の前提条件）
└── 共起ネットワーク.ipynb         # 共起ネットワーク分析スクリプト（分析スクリプトの例）
```

各ディレクトリの役割：
- `text_data`: 分析対象のテキストデータを格納するディレクトリです。用途に応じて適切なサブディレクトリを作成して管理します。
- `processed_data`: 「テキストファイル解析」スクリプトの実行結果を格納する親ディレクトリです。解析を行ったテキストデータごとに子ディレクトリが自動的に作成され、その中に以下の2つのファイルが保存されます：
  - `.spacy`: 解析結果のバイナリファイル
  - `.txt`: 解析対象のファイル名が記載されたテキストファイル

## 使用方法

### 重要な前提条件
本ツールを使用するには、まず「テキストファイル解析.ipynb」スクリプトを実行して解析済みデータを作成する必要があります。このスクリプトは、spaCyの統計モデルを用いてテキストを解析し、その結果を`.spacy`ファイル（解析結果のバイナリファイル）と`.txt`ファイル（解析したファイル名のリスト）として保存します。これらの解析済みデータは、後続の全ての分析スクリプトで使用されます。

### 基本的な使用手順
1. テキストデータを`text_data`ディレクトリ内の適切なサブディレクトリに配置
2. `テキストファイル解析.ipynb`を実行してテキストの基本解析を実施
   - 解析結果は`processed_data`ディレクトリ内に保存されます
3. 目的に応じて各分析スクリプトを選択・実行
   - 各スクリプトは保存された解析済みデータを読み込んで分析を行います

## 注意事項
- 「テキストファイル解析」スクリプトの実行が他の分析の前提条件となります
- 解析単位や前処理方法により、結果に微細な差異が生じる可能性があります
- より高度な統計分析や特定目的の分析には、スクリプトの拡張が必要な場合があります
